#!/usr/bin/env python3
"""
Ralph Guard - Hook script for enforcing Ralph workflow rules.

Only runs when FLOW_RALPH=1 is set. Exits silently otherwise to avoid
polluting context for non-Ralph users.

Enforces:
- No --json flag on chat-send (suppresses review text)
- No --new-chat on re-reviews (loses reviewer context)
- Receipt must be written after SHIP verdict
- Validates flowctl command patterns
"""

import json
import os
import re
import subprocess
import sys
from datetime import datetime
from pathlib import Path


def get_state_file(session_id: str) -> Path:
    """Get state file path for this session."""
    return Path(f"/tmp/ralph-guard-{session_id}.json")


def load_state(session_id: str) -> dict:
    """Load session state."""
    state_file = get_state_file(session_id)
    if state_file.exists():
        try:
            state = json.loads(state_file.read_text(), object_hook=state_decoder)
            # Ensure all expected keys exist
            state.setdefault("chats_sent", 0)
            state.setdefault("last_verdict", None)
            state.setdefault("window", None)
            state.setdefault("tab", None)
            state.setdefault("chat_send_succeeded", False)
            state.setdefault("flowctl_done_called", set())
            return state
        except:
            pass
    return {
        "chats_sent": 0,
        "last_verdict": None,
        "window": None,
        "tab": None,
        "chat_send_succeeded": False,  # Track if chat-send actually returned review text
        "flowctl_done_called": set(),   # Track tasks that had flowctl done called
    }


def state_decoder(obj):
    """JSON decoder that handles sets."""
    if "flowctl_done_called" in obj and isinstance(obj["flowctl_done_called"], list):
        obj["flowctl_done_called"] = set(obj["flowctl_done_called"])
    return obj


def state_encoder(obj):
    """JSON encoder that handles sets."""
    if isinstance(obj, set):
        return list(obj)
    raise TypeError(f"Object of type {type(obj)} is not JSON serializable")


def save_state(session_id: str, state: dict) -> None:
    """Save session state."""
    state_file = get_state_file(session_id)
    state_file.write_text(json.dumps(state, default=state_encoder))


def output_block(reason: str) -> None:
    """Output blocking response (exit code 2 style via stderr)."""
    print(reason, file=sys.stderr)
    sys.exit(2)


# --- Memory helpers ---

def get_repo_root() -> Path:
    """Find git repo root."""
    try:
        result = subprocess.run(
            ["git", "rev-parse", "--show-toplevel"],
            capture_output=True, text=True, check=True
        )
        return Path(result.stdout.strip())
    except subprocess.CalledProcessError:
        return Path.cwd()


def is_memory_enabled() -> bool:
    """Check if memory is enabled in .flow/config.json."""
    config_path = get_repo_root() / ".flow" / "config.json"
    if not config_path.exists():
        return False
    try:
        config = json.loads(config_path.read_text())
        return config.get("memory", {}).get("enabled", False)
    except (json.JSONDecodeError, Exception):
        return False


def extract_feedback(response_text: str) -> dict:
    """Parse NEEDS_WORK/MAJOR_RETHINK response into structured feedback.

    Returns dict with: verdict, issues (list of {issue, fix, context})
    """
    feedback = {
        "verdict": None,
        "issues": []
    }

    # Extract verdict
    verdict_match = re.search(r"<verdict>(NEEDS_WORK|MAJOR_RETHINK)</verdict>", response_text)
    if verdict_match:
        feedback["verdict"] = verdict_match.group(1)

    # Extract issues - look for common patterns in review feedback
    # Pattern 1: **Issue**: ... **Fix**: ...
    issue_fix_pairs = re.findall(
        r"\*\*(?:Issue|Problem|Bug|Error)[:\s]*\*\*\s*([^\n*]+).*?"
        r"\*\*(?:Fix|Solution|Suggestion)[:\s]*\*\*\s*([^\n*]+)",
        response_text, re.IGNORECASE | re.DOTALL
    )
    for issue, fix in issue_fix_pairs:
        feedback["issues"].append({
            "issue": issue.strip(),
            "fix": fix.strip(),
            "context": ""
        })

    # Pattern 2: Numbered list items with issues
    # e.g., "1. Missing X - should do Y"
    numbered_items = re.findall(
        r"^\s*\d+\.\s+(.+?)(?:\s*[-–—]\s*(.+))?$",
        response_text, re.MULTILINE
    )
    for item in numbered_items:
        issue_text = item[0].strip()
        fix_text = item[1].strip() if item[1] else ""
        # Skip if too short or generic
        if len(issue_text) > 20 and issue_text not in [i["issue"] for i in feedback["issues"]]:
            feedback["issues"].append({
                "issue": issue_text,
                "fix": fix_text,
                "context": ""
            })

    # Pattern 3: Look for bullet points with actionable items
    bullet_items = re.findall(
        r"^\s*[-•]\s+(.+)$",
        response_text, re.MULTILINE
    )
    for item in bullet_items:
        item_text = item.strip()
        # Only add if it looks like a specific issue (not generic advice)
        if (len(item_text) > 30 and
            any(kw in item_text.lower() for kw in ["should", "must", "need", "missing", "wrong", "incorrect", "use"]) and
            item_text not in [i["issue"] for i in feedback["issues"]]):
            feedback["issues"].append({
                "issue": item_text,
                "fix": "",
                "context": ""
            })

    return feedback


def is_learnable(issue: dict) -> bool:
    """Filter to actionable patterns that models tend to miss.

    Returns True if the issue is worth capturing (framework patterns, API quirks, etc.)
    Returns False for one-off typos, obvious bugs, or generic advice.
    """
    issue_text = issue.get("issue", "").lower()
    fix_text = issue.get("fix", "").lower()
    combined = issue_text + " " + fix_text

    # Reject: Too short to be meaningful
    if len(issue_text) < 15:
        return False

    # Reject: Generic/vague (no specific actionable fix)
    vague_patterns = [
        r"^improve",
        r"^consider",
        r"^maybe",
        r"^could be better",
        r"^minor",
        r"^typo",
        r"^spelling",
        r"^formatting",
        r"^style",
    ]
    for pattern in vague_patterns:
        if re.search(pattern, issue_text):
            return False

    # Accept: Framework/library patterns
    framework_keywords = [
        "react", "vue", "angular", "next", "nuxt", "svelte",
        "node", "express", "fastapi", "django", "flask",
        "typescript", "python", "rust", "go", "java",
        "import", "export", "module", "package",
        "hook", "middleware", "component", "directive",
    ]
    if any(kw in combined for kw in framework_keywords):
        return True

    # Accept: API/command patterns
    api_keywords = [
        "api", "endpoint", "route", "request", "response",
        "flowctl", "rp-cli", "command", "flag", "option",
        "config", "setting", "env", "environment",
    ]
    if any(kw in combined for kw in api_keywords):
        return True

    # Accept: Pattern/convention mentions
    convention_keywords = [
        "convention", "pattern", "structure", "must use",
        "should use", "always", "never", "required",
        "format", "schema", "validate",
    ]
    if any(kw in combined for kw in convention_keywords):
        return True

    # Accept: Specific error types
    error_keywords = [
        "error", "exception", "failure", "missing",
        "undefined", "null", "not found", "invalid",
    ]
    if any(kw in combined for kw in error_keywords) and len(fix_text) > 10:
        return True

    # Default: Reject (better to be selective)
    return False


def classify_issue(issue: dict) -> str:
    """Classify issue into category for memory entry."""
    combined = (issue.get("issue", "") + " " + issue.get("fix", "")).lower()

    if any(kw in combined for kw in ["react", "vue", "angular", "next", "svelte", "component", "hook"]):
        return "framework"
    if any(kw in combined for kw in ["api", "endpoint", "flowctl", "rp-cli", "command", "flag"]):
        return "api"
    if any(kw in combined for kw in ["convention", "pattern", "always", "never", "must"]):
        return "convention"
    if any(kw in combined for kw in ["edge", "case", "empty", "null", "undefined"]):
        return "edge-case"

    return "general"


def get_current_task_id() -> str:
    """Get current task ID from Ralph's environment.

    Returns task ID from FLOW_CURRENT_TASK env var, or 'unknown' if not set.
    Note: In Ralph mode, the harness sets this env var. No fallback query
    since .flow/bin/flowctl may not exist (setup is optional).
    """
    return os.environ.get("FLOW_CURRENT_TASK", "unknown")


def append_to_pitfalls(issue: dict, task_id: str, category: str) -> bool:
    """Append a learnable issue to .flow/memory/pitfalls.md.

    Returns True if successfully appended, False otherwise.
    """
    repo_root = get_repo_root()
    pitfalls_path = repo_root / ".flow" / "memory" / "pitfalls.md"

    # Ensure memory dir exists
    if not pitfalls_path.parent.exists():
        return False

    # Format the entry
    today = datetime.utcnow().strftime("%Y-%m-%d")
    entry = f"""
## {today} {task_id} impl-review [{category}]
**Issue**: {issue.get("issue", "").strip()}
**Fix**: {issue.get("fix", "").strip() or "(see context)"}
**Context**: {issue.get("context", "").strip() or "From NEEDS_WORK review feedback"}
"""

    # Append to file
    try:
        with pitfalls_path.open("a", encoding="utf-8") as f:
            f.write(entry)
        return True
    except Exception as e:
        # Log error but don't fail the hook
        with Path("/tmp/ralph-guard-debug.log").open("a") as f:
            f.write(f"  -> Memory append failed: {e}\n")
        return False


def output_json(data: dict) -> None:
    """Output JSON response."""
    print(json.dumps(data))
    sys.exit(0)


def handle_pre_tool_use(data: dict) -> None:
    """Handle PreToolUse event - validate commands before execution."""
    tool_input = data.get("tool_input", {})
    command = tool_input.get("command", "")
    session_id = data.get("session_id", "unknown")

    # Check for chat-send commands
    if "chat-send" in command:
        # Block --json flag
        if re.search(r"chat-send.*--json", command):
            output_block(
                "BLOCKED: Do not use --json with chat-send. "
                "It suppresses the review text. Remove --json flag."
            )

        # Check for --new-chat on re-reviews
        if "--new-chat" in command:
            state = load_state(session_id)
            if state["chats_sent"] > 0:
                output_block(
                    "BLOCKED: Do not use --new-chat for re-reviews. "
                    "Stay in the same chat so reviewer has context. "
                    "Remove --new-chat flag."
                )

    # Validate setup-review usage
    if "setup-review" in command:
        if not re.search(r"--repo-root", command):
            output_block(
                "BLOCKED: setup-review requires --repo-root flag. "
                "Use: setup-review --repo-root \"$REPO_ROOT\" --summary \"...\""
            )
        if not re.search(r"--summary", command):
            output_block(
                "BLOCKED: setup-review requires --summary flag. "
                "Use: setup-review --repo-root \"$REPO_ROOT\" --summary \"...\""
            )

    # Validate select-add has --window and --tab
    if "select-add" in command:
        if not re.search(r"--window", command):
            output_block(
                "BLOCKED: select-add requires --window flag. "
                "Use: select-add --window \"$W\" --tab \"$T\" <path>"
            )

    # Block receipt writes unless chat-send has succeeded + validate format
    receipt_path = os.environ.get("REVIEW_RECEIPT_PATH", "")
    if receipt_path:
        # Check if this command writes to a receipt path
        receipt_dir = os.path.dirname(receipt_path)
        is_receipt_write = receipt_dir and (
            re.search(rf">\s*['\"]?{re.escape(receipt_dir)}", command) or
            re.search(r">\s*['\"]?.*receipts/.*\.json", command) or
            re.search(r"cat\s*>\s*.*receipt", command, re.I)
        )
        if is_receipt_write:
            state = load_state(session_id)
            if not state.get("chat_send_succeeded"):
                output_block(
                    "BLOCKED: Cannot write receipt before review completes. "
                    "You must run 'flowctl rp chat-send' and receive a review response "
                    "before writing the receipt. The review has not been sent yet."
                )
            # Validate receipt has required 'id' field
            if '"id"' not in command and "'id'" not in command:
                output_block(
                    "BLOCKED: Receipt JSON is missing required 'id' field. "
                    "Receipt must include: {\"type\":\"...\",\"id\":\"<TASK_OR_EPIC_ID>\",...} "
                    "Copy the exact command from the prompt template."
                )
            # For impl receipts, verify flowctl done was called
            if "impl_review" in command:
                # Extract task id from receipt
                id_match = re.search(r'"id"\s*:\s*"([^"]+)"', command)
                if id_match:
                    task_id = id_match.group(1)
                    done_set = state.get("flowctl_done_called", set())
                    if isinstance(done_set, list):
                        done_set = set(done_set)
                    if task_id not in done_set:
                        output_block(
                            f"BLOCKED: Cannot write impl receipt for {task_id} - flowctl done was not called. "
                            f"You MUST run 'flowctl done {task_id} --evidence ...' BEFORE writing the receipt. "
                            "The task is NOT complete until flowctl done succeeds."
                        )

    # All checks passed
    sys.exit(0)


def handle_post_tool_use(data: dict) -> None:
    """Handle PostToolUse event - track state and provide feedback."""
    tool_input = data.get("tool_input", {})
    tool_response = data.get("tool_response", {})
    command = tool_input.get("command", "")
    session_id = data.get("session_id", "unknown")

    # Get response text
    response_text = ""
    if isinstance(tool_response, dict):
        response_text = tool_response.get("stdout", "") or str(tool_response)
    elif isinstance(tool_response, str):
        response_text = tool_response

    state = load_state(session_id)

    # Track chat-send calls - must have actual review text, not null
    if "chat-send" in command:
        # Check for successful chat (has "Chat Send" and review text, not null)
        if "Chat Send" in response_text and '{"chat": null}' not in response_text:
            state["chats_sent"] = state.get("chats_sent", 0) + 1
            state["chat_send_succeeded"] = True
            save_state(session_id, state)
        elif '{"chat": null}' in response_text or '{"chat":null}' in response_text:
            # Failed - --json was used incorrectly
            state["chat_send_succeeded"] = False
            save_state(session_id, state)

    # Track flowctl done calls - match flowctl.py, ./flowctl, etc.
    if "flowctl" in command and " done " in command:
        # Debug logging
        with Path("/tmp/ralph-guard-debug.log").open("a") as f:
            f.write(f"  -> flowctl done detected in: {command[:100]}...\n")

        # Extract task ID from command - skip flags (start with -)
        # Match: flowctl done <task_id> OR flowctl.py done <task_id>
        done_match = re.search(r"flowctl(?:\.py)?\s+done\s+([a-zA-Z0-9][a-zA-Z0-9._-]*)", command)
        if done_match:
            task_id = done_match.group(1)
            with Path("/tmp/ralph-guard-debug.log").open("a") as f:
                f.write(f"  -> Extracted task_id: {task_id}, response has 'status': {'status' in response_text.lower()}\n")

            # Check response indicates success (has "status", "done", "updated", or "completed")
            response_lower = response_text.lower()
            if "status" in response_lower or "done" in response_lower or "updated" in response_lower or "completed" in response_lower:
                done_set = state.get("flowctl_done_called", set())
                if isinstance(done_set, list):
                    done_set = set(done_set)
                done_set.add(task_id)
                state["flowctl_done_called"] = done_set
                save_state(session_id, state)
                with Path("/tmp/ralph-guard-debug.log").open("a") as f:
                    f.write(f"  -> Added {task_id} to flowctl_done_called: {done_set}\n")

    # Track receipt writes - reset chat_send_succeeded after write
    receipt_path = os.environ.get("REVIEW_RECEIPT_PATH", "")
    if receipt_path and receipt_path in command and ">" in command:
        state["chat_send_succeeded"] = False  # Reset for next review
        save_state(session_id, state)

    # Track setup-review output (W= T=)
    if "setup-review" in command:
        w_match = re.search(r"W=(\d+)", response_text)
        t_match = re.search(r"T=([A-F0-9-]+)", response_text, re.I)
        if w_match:
            state["window"] = w_match.group(1)
        if t_match:
            state["tab"] = t_match.group(1)
        save_state(session_id, state)

    # Check for verdict in response
    verdict_match = re.search(r"<verdict>(SHIP|NEEDS_WORK|MAJOR_RETHINK)</verdict>", response_text)
    if verdict_match:
        state["last_verdict"] = verdict_match.group(1)
        save_state(session_id, state)

        # If SHIP, remind about receipt
        if verdict_match.group(1) == "SHIP":
            receipt_path = os.environ.get("REVIEW_RECEIPT_PATH", "")
            if receipt_path and not Path(receipt_path).exists():
                # Provide feedback to Claude
                output_json({
                    "hookSpecificOutput": {
                        "hookEventName": "PostToolUse",
                        "additionalContext": (
                            f"IMPORTANT: SHIP verdict received. You MUST now write the receipt. "
                            f"Run this command:\n"
                            f"mkdir -p \"$(dirname '{receipt_path}')\" && "
                            f"echo '{{\"type\":\"impl_review\",\"mode\":\"rp\",\"timestamp\":\"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\"}}' > '{receipt_path}'"
                        )
                    }
                })

        # Capture learnings from NEEDS_WORK/MAJOR_RETHINK to memory
        elif verdict_match.group(1) in ("NEEDS_WORK", "MAJOR_RETHINK"):
            if is_memory_enabled():
                try:
                    feedback = extract_feedback(response_text)
                    task_id = get_current_task_id()
                    captured = 0
                    for issue in feedback.get("issues", []):
                        if is_learnable(issue):
                            category = classify_issue(issue)
                            if append_to_pitfalls(issue, task_id, category):
                                captured += 1
                    # Log for debugging
                    with Path("/tmp/ralph-guard-debug.log").open("a") as f:
                        f.write(f"  -> Memory: captured {captured}/{len(feedback.get('issues', []))} issues from {feedback.get('verdict')} review\n")
                except Exception as e:
                    with Path("/tmp/ralph-guard-debug.log").open("a") as f:
                        f.write(f"  -> Memory capture error: {e}\n")

    elif "chat-send" in command and "Chat Send" in response_text:
        # chat-send returned but no verdict tag found
        # Check for informal approvals that should have been verdict tags
        if re.search(r"\bLGTM\b|\bLooks good\b|\bApproved\b|\bNo issues\b", response_text, re.I):
            output_json({
                "hookSpecificOutput": {
                    "hookEventName": "PostToolUse",
                    "additionalContext": (
                        "WARNING: Reviewer responded with informal approval (LGTM/Looks good) "
                        "but did NOT use the required <verdict>SHIP</verdict> tag. "
                        "This means your review prompt was incorrect. "
                        "You MUST use /flow-next:impl-review skill which has the correct prompt format. "
                        "Do NOT improvise review prompts. Re-invoke the skill and try again."
                    )
                }
            })

    # Check for {"chat": null} which indicates --json was used incorrectly
    if '{"chat":' in response_text or '{"chat": ' in response_text:
        if "null" in response_text:
            output_json({
                "decision": "block",
                "reason": (
                    "ERROR: chat-send returned {\"chat\": null} which means --json was used. "
                    "This suppresses the review text. Re-run without --json flag."
                )
            })

    sys.exit(0)


def handle_stop(data: dict) -> None:
    """Handle Stop event - verify receipt written before allowing stop."""
    session_id = data.get("session_id", "unknown")
    stop_hook_active = data.get("stop_hook_active", False)

    # Prevent infinite loops
    if stop_hook_active:
        sys.exit(0)

    receipt_path = os.environ.get("REVIEW_RECEIPT_PATH", "")

    if receipt_path:
        if not Path(receipt_path).exists():
            # Block stop - receipt not written
            output_json({
                "decision": "block",
                "reason": (
                    f"Cannot stop: Review receipt not written. "
                    f"You must write the receipt to: {receipt_path}\n"
                    f"Run: mkdir -p \"$(dirname '{receipt_path}')\" && "
                    f"echo '{{\"type\":\"impl_review\",\"mode\":\"rp\",\"timestamp\":\"'$(date -u +%Y-%m-%dT%H:%M:%SZ)'\"}}' > '{receipt_path}'"
                )
            })

    # Clean up state file
    state_file = get_state_file(session_id)
    if state_file.exists():
        state_file.unlink()

    sys.exit(0)


def handle_subagent_stop(data: dict) -> None:
    """Handle SubagentStop event - same as Stop for subagents."""
    handle_stop(data)


def main():
    # Debug logging - always write to see if hook is being called
    debug_file = Path("/tmp/ralph-guard-debug.log")
    with debug_file.open("a") as f:
        f.write(f"[{os.environ.get('FLOW_RALPH', 'unset')}] Hook called\n")

    # Early exit if not in Ralph mode - no output, no context pollution
    if os.environ.get("FLOW_RALPH") != "1":
        with debug_file.open("a") as f:
            f.write("  -> Exiting: FLOW_RALPH not set to 1\n")
        sys.exit(0)

    # Read input
    try:
        data = json.load(sys.stdin)
    except json.JSONDecodeError:
        with debug_file.open("a") as f:
            f.write("  -> Exiting: JSON decode error\n")
        sys.exit(0)

    event = data.get("hook_event_name", "")
    tool_name = data.get("tool_name", "")

    with debug_file.open("a") as f:
        f.write(f"  -> Event: {event}, Tool: {tool_name}\n")

    # Only process Bash tool calls for Pre/Post
    if event in ("PreToolUse", "PostToolUse") and tool_name != "Bash":
        with debug_file.open("a") as f:
            f.write(f"  -> Skipping: not Bash\n")
        sys.exit(0)

    # Route to handler
    if event == "PreToolUse":
        handle_pre_tool_use(data)
    elif event == "PostToolUse":
        handle_post_tool_use(data)
    elif event == "Stop":
        handle_stop(data)
    elif event == "SubagentStop":
        handle_subagent_stop(data)
    else:
        sys.exit(0)


if __name__ == "__main__":
    main()
